import streamlit as st
import numpy as np
from PIL import Image
import pandas as pd
import os

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ environment ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î memory
os.environ['TORCH_NUM_THREADS'] = '1'
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞ import dependencies ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    st.warning("‚ö†Ô∏è OpenCV ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô - ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô")

try:
    import torch
    torch.set_num_threads(1)
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    st.error("‚ö†Ô∏è PyTorch ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å‡πÑ‡∏ß‡πâ
try:
    from config import (
        CLASSES, WASTE_CATEGORIES, CSS_STYLES, HIDE_STREAMLIT_STYLE, 
        DEFAULT_CONFIDENCE, DEFAULT_IOU, SUPPORTED_IMAGE_TYPES
    )
    from utils import (
        find_model_files, load_model, process_detections, 
        calculate_environmental_score, generate_recommendations, 
        create_summary_table, cleanup_memory
    )
    from ui_components import (
        render_header, render_waste_info_section, render_sidebar_controls,
        render_statistics_cards, render_results_table, render_charts,
        render_recommendations_section, render_detailed_results, 
        render_help_section, render_footer
    )
except ImportError as e:
    st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏î‡πâ: {e}")
    st.info("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå config.py, utils.py ‡πÅ‡∏•‡∏∞ ui_components.py ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô")
    st.stop()

def convert_image_for_processing(image):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ cv2"""
    try:
        # ‡πÅ‡∏õ‡∏•‡∏á PIL Image ‡πÄ‡∏õ‡πá‡∏ô numpy array
        image_array = np.array(image)
        
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ RGBA ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô RGB
        if len(image_array.shape) == 3 and image_array.shape[-1] == 4:
            image_array = image_array[:, :, :3]
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ ‡∏´‡∏≤‡∏Å‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡πÉ‡∏´‡πâ‡∏¢‡πà‡∏≠‡∏Ç‡∏ô‡∏≤‡∏î
        height, width = image_array.shape[:2]
        max_size = 1024
        
        if height > max_size or width > max_size:
            from PIL import Image
            image_pil = Image.fromarray(image_array)
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏°‡πà‡πÇ‡∏î‡∏¢‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô
            if height > width:
                new_height = max_size
                new_width = int(width * max_size / height)
            else:
                new_width = max_size
                new_height = int(height * max_size / width)
            
            image_pil = image_pil.resize((new_width, new_height), Image.Resampling.LANCZOS)
            image_array = np.array(image_pil)
            
            st.info(f"üìè ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å {width}x{height} ‡πÄ‡∏õ‡πá‡∏ô {new_width}x{new_height}")
        
        return image_array
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: {e}")
        return np.array(image)

def process_model_results(results, original_image):
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó"""
    try:
        if not results or len(results) == 0:
            st.warning("‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•")
            return None
        
        result = results[0]
        
        # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏°‡∏µ annotation
        annotated_image = None
        
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô plot ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö YOLO)
        if hasattr(result, 'plot') and CV2_AVAILABLE:
            try:
                annotated_image = result.plot()
                if len(annotated_image.shape) == 3 and annotated_image.shape[2] == 3:
                    # ‡πÅ‡∏õ‡∏•‡∏á BGR ‡πÄ‡∏õ‡πá‡∏ô RGB
                    annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)
                st.success("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ annotation ‡∏î‡πâ‡∏ß‡∏¢ OpenCV")
            except Exception as e:
                st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ OpenCV plot: {e}")
                annotated_image = None
        
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
        if annotated_image is None and hasattr(result, 'orig_img') and result.orig_img is not None:
            try:
                annotated_image = np.array(result.orig_img)
                if len(annotated_image.shape) == 3 and annotated_image.shape[2] == 3:
                    # ‡πÅ‡∏õ‡∏•‡∏á BGR ‡πÄ‡∏õ‡πá‡∏ô RGB ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
                    annotated_image = annotated_image[:, :, ::-1]
                st.info("üì∑ ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•")
            except Exception as e:
                st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•: {e}")
                annotated_image = None
        
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡∏ß‡∏≤‡∏î bounding boxes ‡∏î‡πâ‡∏ß‡∏¢ PIL (fallback)
        if annotated_image is None:
            try:
                annotated_image = draw_detections_pil(original_image, result)
                if annotated_image is not None:
                    st.info("üé® ‡∏ß‡∏≤‡∏î bounding boxes ‡∏î‡πâ‡∏ß‡∏¢ PIL")
            except Exception as e:
                st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏≤‡∏î‡∏î‡πâ‡∏ß‡∏¢ PIL: {e}")
        
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 4: ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö (last resort)
        if annotated_image is None:
            annotated_image = np.array(original_image)
            st.warning("‚ö†Ô∏è ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö (‡πÑ‡∏°‡πà‡∏°‡∏µ annotation)")
        
        return annotated_image
        
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: {e}")
        return np.array(original_image)

def draw_detections_pil(image, result):
    """‡∏ß‡∏≤‡∏î bounding boxes ‡∏î‡πâ‡∏ß‡∏¢ PIL ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà OpenCV ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"""
    try:
        from PIL import Image as PILImage, ImageDraw, ImageFont
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô PIL Image
        if isinstance(image, np.ndarray):
            pil_image = PILImage.fromarray(image)
        else:
            pil_image = image.copy()
        
        draw = ImageDraw.Draw(pil_image)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ detections ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if hasattr(result, 'boxes') and result.boxes is not None and len(result.boxes) > 0:
            detections = result.boxes
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° font (‡πÉ‡∏ä‡πâ default ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ)
            try:
                font = ImageFont.load_default()
            except:
                font = None
            
            colors = ["red", "blue", "green", "orange", "purple", "yellow", 
                     "pink", "brown", "gray", "cyan", "magenta", "lime"]
            
            for i, detection in enumerate(detections):
                try:
                    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• detection
                    if hasattr(detection, 'cls'):
                        class_id = int(detection.cls[0])
                        confidence = float(detection.conf[0])
                        
                        # bounding box
                        if hasattr(detection.xyxy[0], 'cpu'):
                            bbox = detection.xyxy[0].cpu().numpy()
                        else:
                            bbox = detection.xyxy[0].numpy()
                        
                        x1, y1, x2, y2 = map(int, bbox)
                        
                        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏µ‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™
                        color = colors[class_id % len(colors)]
                        class_name = CLASSES[class_id] if class_id < len(CLASSES) else f"Class_{class_id}"
                        
                        # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö
                        draw.rectangle([(x1, y1), (x2, y2)], outline=color, width=2)
                        
                        # ‡∏ß‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
                        text = f"{class_name}: {confidence:.2f}"
                        text_bbox = draw.textbbox((x1, y1-20), text, font=font) if font else (x1, y1-20, x1+100, y1)
                        
                        # ‡∏ß‡∏≤‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
                        draw.rectangle(text_bbox, fill=color)
                        draw.text((x1, y1-20), text, fill="white", font=font)
                        
                except Exception as e:
                    st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏≤‡∏î detection {i}: {e}")
                    continue
        
        return np.array(pil_image)
        
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏î‡∏î‡πâ‡∏ß‡∏¢ PIL: {e}")
        return None

def display_model_info(model, model_path):
    """‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    try:
        model_name = os.path.basename(model_path)
        file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
        
        with st.expander("üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•"):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå", model_name)
            with col2:
                st.metric("‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå", f"{file_size:.1f} MB")
            with col3:
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏°‡πÄ‡∏î‡∏•
                if hasattr(model, 'model_type'):
                    model_type = model.model_type
                else:
                    model_type = "YOLO"
                st.metric("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó", model_type)
            
            # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
            st.markdown(f"""
            **‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:**
            - üìÅ Path: `{model_path}`
            - üéØ ‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö: {len(CLASSES)} ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
            - üíæ Memory: CPU Only (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î resources)
            """)
            
    except Exception as e:
        st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ: {e}")

def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô"""
    
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
    st.set_page_config(
        page_title="Waste Detection App",
        page_icon="üóÇÔ∏è",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ‡πÉ‡∏ä‡πâ CSS
    st.markdown(HIDE_STREAMLIT_STYLE, unsafe_allow_html=True)
    st.markdown(CSS_STYLES, unsafe_allow_html=True)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á
    render_header()
    
    # ‡πÅ‡∏ñ‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≤‡∏á
    controls = render_sidebar_controls()
    
    # ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
    with st.sidebar:
        st.markdown("### ü§ñ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•")
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•
        model_files = find_model_files()
        
        if model_files:
            selected_model = st.selectbox(
                "‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ:",
                model_files,
                help="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• .pt ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ"
            )
        else:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• .pt ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå")
            st.info("""
            üí° ‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
            - `./your_model.pt`
            - `./models/your_model.pt`  
            - `./weights/your_model.pt`
            """)
            
            selected_model = st.text_input(
                "‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏∏ Path ‡πÇ‡∏°‡πÄ‡∏î‡∏•:",
                value="yolov8n.pt",
                help="‡∏£‡∏∞‡∏ö‡∏∏ path ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß"
            )
        
        # ‡∏õ‡∏∏‡πà‡∏°‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•
        if st.button("üîÑ ‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•"):
            st.cache_data.clear()
            st.rerun()
    
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model = None
    model_status = "‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•"
    
    if selected_model:
        with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• {os.path.basename(selected_model)}..."):
            model, model_status = load_model(selected_model)
            
            # ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå memory ‡∏´‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
            cleanup_memory()
    
    with st.sidebar:
        if model:
            st.success(model_status)
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•
            display_model_info(model, selected_model)
            
            # ‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÅ‡∏Ñ‡∏ä
            if st.button("üóëÔ∏è ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡πÅ‡∏Ñ‡∏ä"):
                st.cache_resource.clear()
                cleanup_memory()
                st.success("‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡πÅ‡∏Ñ‡∏ä‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
                st.rerun()
        else:
            st.error(model_status)
            
            if "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå" in model_status:
                st.info("üí° ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
            elif "Dependencies" in model_status:
                st.info("üí° ‡∏£‡∏≠‡πÉ‡∏´‡πâ Streamlit Cloud ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á libraries ‡πÄ‡∏™‡∏£‡πá‡∏à")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡∏¢‡∏∞
    render_waste_info_section()
    
    # ‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ
    st.markdown('<h2 class="sub-header">üì§ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ç‡∏¢‡∏∞</h2>', unsafe_allow_html=True)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
    with st.expander("üí° ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥"):
        st.markdown("""
        **‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏î‡∏µ:**
        - üì∏ ‡πÅ‡∏™‡∏á‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡πÅ‡∏•‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
        - üéØ ‡∏Ç‡∏¢‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Å‡∏£‡∏≠‡∏ö
        - üìè ‡πÑ‡∏°‡πà‡πÄ‡∏ö‡∏•‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏≠‡∏µ‡∏¢‡∏á
        - üîç ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 10MB
        
        **‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á:**
        - üåÉ ‡∏£‡∏π‡∏õ‡∏°‡∏∑‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏™‡∏á‡∏ô‡πâ‡∏≠‡∏¢
        - üîÑ ‡∏£‡∏π‡∏õ‡πÄ‡∏ö‡∏•‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î
        - üìê ‡∏Ç‡∏¢‡∏∞‡∏≠‡∏¢‡∏π‡πà‡∏°‡∏∏‡∏°‡∏£‡∏π‡∏õ
        - üñºÔ∏è ‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏¥‡πà‡∏á‡∏ö‡∏î‡∏ö‡∏±‡∏á
        """)
    
    uploaded_file = st.file_uploader(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ç‡∏¢‡∏∞‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó",
        type=SUPPORTED_IMAGE_TYPES,
        help=f"‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: {', '.join([ext.upper() for ext in SUPPORTED_IMAGE_TYPES])}"
    )
    
    if uploaded_file is not None:
        if model is None:
            st.error("‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            st.info("üí° ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß")
            return
            
        # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### üì∏ ‡∏£‡∏π‡∏õ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö")
            try:
                image = Image.open(uploaded_file)
                st.image(image, caption="‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î", use_column_width=True)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
                with st.expander("üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"):
                    st.write(f"üìè ‡∏Ç‡∏ô‡∏≤‡∏î: {image.size[0]} x {image.size[1]} pixels")
                    st.write(f"üé® ‡πÇ‡∏´‡∏°‡∏î: {image.mode}")
                    st.write(f"üìÅ ‡∏ä‡∏ô‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå: {image.format}")
                    
                    if hasattr(uploaded_file, 'size'):
                        file_size = uploaded_file.size / 1024  # KB
                        st.write(f"üíæ ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå: {file_size:.1f} KB")
                        
            except Exception as e:
                st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ: {e}")
                return
        
        # ‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])
        with col_btn2:
            process_button = st.button(
                "üîç ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡∏¢‡∏∞", 
                type="primary", 
                use_container_width=True
            )
        
        if process_button:
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•... ‡πÇ‡∏õ‡∏£‡∏î‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà"):
                try:
                    # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
                    with st.status("‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û...") as status:
                        image_array = convert_image_for_processing(image)
                        status.update(label="‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏£‡πá‡∏à", state="complete")
                    
                    # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•
                    with st.status("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ AI...") as status:
                        results = model(
                            image_array, 
                            conf=controls["confidence"], 
                            iou=controls["iou"]
                        )
                        status.update(label="‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à", state="complete")
                    
                    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                    with st.status("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå...") as status:
                        annotated_image = process_model_results(results, image)
                        status.update(label="‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡πÄ‡∏™‡∏£‡πá‡∏à", state="complete")
                    
                    with col2:
                        st.markdown("### üéØ ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö")
                        if annotated_image is not None:
                            st.image(annotated_image, caption="‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡πâ‡∏ß", use_column_width=True)
                        else:
                            st.image(image, caption="‡∏£‡∏π‡∏õ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö (‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á annotation ‡πÑ‡∏î‡πâ)", use_column_width=True)
                    
                    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
                    with st.status("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå...") as status:
                        class_counts, category_counts, detailed_data = process_detections(
                            results, controls["confidence"], controls["iou"]
                        )
                        status.update(label="‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏™‡∏£‡πá‡∏à", state="complete")
                    
                    if class_counts:
                        st.markdown('<div class="result-box">', unsafe_allow_html=True)
                        st.markdown("### üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡∏¢‡∏∞")
                        
                        total_detections = sum([data["count"] for data in class_counts.values()])
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏£‡∏∏‡∏õ
                        st.success(f"üéâ ‡∏û‡∏ö‡∏Ç‡∏¢‡∏∞‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î **{total_detections}** ‡∏ä‡∏¥‡πâ‡∏ô ‡∏à‡∏≤‡∏Å **{len(class_counts)}** ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó")
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
                        render_statistics_cards(category_counts, total_detections)
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                        results_data = create_summary_table(class_counts)
                        render_results_table(results_data)
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü
                        render_charts(class_counts, category_counts)
                        
                        # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°
                        recommendations = generate_recommendations(category_counts)
                        eco_score, eco_message = calculate_environmental_score(
                            category_counts, total_detections
                        )
                        render_recommendations_section(recommendations, eco_score, eco_message)
                        
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
                        render_detailed_results(detailed_data)
                        
                        # ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå memory ‡∏´‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
                        cleanup_memory()
                        
                    else:
                        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡∏¢‡∏∞‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ")
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
                        st.markdown("""
                        ### üí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:
                        - **‡∏•‡∏î‡∏Ñ‡πà‡∏≤ Confidence Threshold** ‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ö‡∏Ç‡πâ‡∏≤‡∏á (‡∏•‡∏≠‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà 0.3)
                        - **‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô** ‡∏°‡∏µ‡πÅ‡∏™‡∏á‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠
                        - **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡∏¢‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Å‡∏£‡∏≠‡∏ö‡∏£‡∏π‡∏õ** 
                        - **‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏≠‡∏∑‡πà‡∏ô** ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡∏¢‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤
                        """)
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î technical
                        with st.expander("üîß ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ"):
                            st.json({
                                "Model": os.path.basename(selected_model),
                                "Confidence Threshold": controls["confidence"],
                                "IoU Threshold": controls["iou"],
                                "Image Size": f"{image.size[0]}x{image.size[1]}",
                                "Processed Size": f"{image_array.shape[1]}x{image_array.shape[0]}",
                                "Results": len(results) if results else 0
                            })
                        
                except Exception as e:
                    st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {e}")
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• debug
                    with st.expander("üîç ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Debug"):
                        st.exception(e)
                        st.json({
                            "Model Type": type(model).__name__,
                            "Model Path": selected_model,
                            "Image Mode": image.mode if 'image' in locals() else 'Unknown',
                            "Image Size": image.size if 'image' in locals() else 'Unknown'
                        })
                    
                    st.info("""
                    ### üõ†Ô∏è ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤:
                    1. **‡∏•‡∏≠‡∏á Refresh ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö** ‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà
                    2. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•** ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢  
                    3. **‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏≠‡∏∑‡πà‡∏ô** (JPG, PNG)
                    4. **‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û** ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏°‡∏≤‡∏Å
                    """)
    
    # ‡∏™‡πà‡∏ß‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠
    render_help_section()
    
    # ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡πâ‡∏≤‡∏¢
    render_footer()

if __name__ == "__main__":
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö dependencies ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏≠‡∏õ
    try:
        main()
    except Exception as e:
        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏≠‡∏õ: {e}")
        st.info("üí° ‡∏•‡∏≠‡∏á refresh ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏£‡∏ö")
        st.exception(e)