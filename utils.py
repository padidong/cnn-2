"""
‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Waste Detection App
"""

import glob
import os
import numpy as np
import streamlit as st
from config import MODEL_EXTENSIONS, WASTE_CATEGORIES, CLASSES

# Import dependencies ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError as e:
    ULTRALYTICS_AVAILABLE = False
    st.error(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î Ultralytics ‡πÑ‡∏î‡πâ: {e}")

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    st.error("‚ö†Ô∏è PyTorch ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

try:
    import timm
    TIMM_AVAILABLE = True
except ImportError:
    TIMM_AVAILABLE = False
    st.warning("‚ö†Ô∏è TIMM ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

def check_dependencies():
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö dependencies ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
    missing_deps = []
    
    if not ULTRALYTICS_AVAILABLE:
        missing_deps.append("ultralytics")
    if not TORCH_AVAILABLE:
        missing_deps.append("torch")
    if not TIMM_AVAILABLE:
        missing_deps.append("timm")
    
    if missing_deps:
        st.error(f"‚ùå Dependencies ‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢‡πÑ‡∏õ: {', '.join(missing_deps)}")
        st.info("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡πÉ‡∏´‡πâ Streamlit Cloud ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á libraries ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏≠‡∏á refresh ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö")
        return False
    
    return True

def find_model_files():
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• .pt ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
    model_files = []
    for pattern in MODEL_EXTENSIONS:
        try:
            model_files.extend(glob.glob(pattern))
        except Exception as e:
            st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö {pattern}: {e}")
    
    return sorted(model_files)

@st.cache_resource(show_spinner=False)
def load_model(model_path):
    """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLO"""
    if not check_dependencies():
        return None, "‚ùå Dependencies ‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô"
    
    try:
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ torch ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î memory
        if TORCH_AVAILABLE:
            torch.set_num_threads(2)
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        if os.path.exists(model_path):
            with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• {os.path.basename(model_path)}..."):
                # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ CPU
                model = YOLO(model_path)
                
                # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ CPU ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î memory
                if hasattr(model.model, 'to'):
                    model.model.to('cpu')
                
                return model, f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {os.path.basename(model_path)}"
        else:
            return None, f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_path}"
            
    except Exception as e:
        error_msg = str(e)
        if "timm" in error_msg.lower():
            return None, "‚ùå ‡∏Ç‡∏≤‡∏î timm library - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à"
        elif "lightning" in error_msg.lower():
            return None, "‚ùå ‡∏Ç‡∏≤‡∏î pytorch-lightning - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à"
        else:
            return None, f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ: {error_msg}"

def process_detections(results, confidence_threshold, iou_threshold):
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
    try:
        if not results or len(results) == 0:
            return None, None, None
            
        detections = results[0].boxes
        if detections is None or len(detections) == 0:
            return None, None, None
        
        class_counts = {}
        category_counts = {"‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÑ‡∏î‡πâ": 0, "‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏•‡∏≤‡∏¢‡πÑ‡∏î‡πâ": 0, "‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢": 0, "‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ": 0}
        detailed_data = []
        
        for i, detection in enumerate(detections):
            try:
                class_id = int(detection.cls[0])
                if class_id < len(CLASSES):
                    class_name = CLASSES[class_id]
                    confidence = float(detection.conf[0])
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö confidence threshold
                    if confidence < confidence_threshold:
                        continue
                    
                    # ‡πÉ‡∏ä‡πâ CPU tensor
                    bbox = detection.xyxy[0].cpu().numpy() if hasattr(detection.xyxy[0], 'cpu') else detection.xyxy[0].numpy()
                    
                    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏¢‡∏∞
                    if class_name in WASTE_CATEGORIES:
                        info = WASTE_CATEGORIES[class_name]
                        category = info["category"]
                        
                        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
                        if class_name not in class_counts:
                            class_counts[class_name] = {"count": 0, "avg_confidence": 0, "category": category}
                        class_counts[class_name]["count"] += 1
                        class_counts[class_name]["avg_confidence"] += confidence
                        category_counts[category] += 1
                        
                        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
                        detailed_data.append({
                            "ID": i+1,
                            "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó": f"{info['icon']} {class_name}",
                            "‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà": category,
                            "‡∏ß‡∏¥‡∏ò‡∏µ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£": info["recycle"],
                            "‡∏ñ‡∏±‡∏á‡∏Ç‡∏¢‡∏∞": f"‡∏ñ‡∏±‡∏á{info['bin_color']}",
                            "Confidence": f"{confidence:.3f}",
                            "X1": int(bbox[0]),
                            "Y1": int(bbox[1]), 
                            "X2": int(bbox[2]),
                            "Y2": int(bbox[3]),
                            "‡∏Ç‡∏ô‡∏≤‡∏î": f"{int(bbox[2]-bbox[0])} x {int(bbox[3]-bbox[1])}"
                        })
                        
            except Exception as e:
                st.warning(f"‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• detection {i}: {e}")
                continue
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ confidence
        for class_name in class_counts:
            if class_counts[class_name]["count"] > 0:
                class_counts[class_name]["avg_confidence"] /= class_counts[class_name]["count"]
        
        return class_counts, category_counts, detailed_data
    
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {e}")
        return None, None, None

def calculate_environmental_score(category_counts, total_detections):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°"""
    if total_detections == 0:
        return 0, "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡∏¢‡∏∞"
    
    recyclable = category_counts.get("‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÑ‡∏î‡πâ", 0)
    biodegradable = category_counts.get("‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏•‡∏≤‡∏¢‡πÑ‡∏î‡πâ", 0)
    
    eco_score = ((recyclable + biodegradable) / total_detections) * 100
    
    if eco_score >= 80:
        return eco_score, "üåü ‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°! ‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏¢‡∏Å‡∏Ç‡∏¢‡∏∞‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏°‡∏≤‡∏Å"
    elif eco_score >= 60:
        return eco_score, "üëç ‡∏î‡∏µ! ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏¢‡∏Å‡∏Ç‡∏¢‡∏∞‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô"
    elif eco_score >= 40:
        return eco_score, "‚ö° ‡∏û‡∏≠‡πÉ‡∏ä‡πâ ‡πÅ‡∏¢‡∏Å‡∏Ç‡∏¢‡∏∞‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô"
    else:
        return eco_score, "üö® ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á! ‡πÅ‡∏¢‡∏Å‡∏Ç‡∏¢‡∏∞‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°"

def generate_recommendations(category_counts):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏∞"""
    recommendations = []
    
    if category_counts.get("‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÑ‡∏î‡πâ", 0) > 0:
        recommendations.append("‚ôªÔ∏è **‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•**: ‡πÅ‡∏¢‡∏Å‡πÉ‡∏™‡πà‡∏ñ‡∏±‡∏á‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á")
    if category_counts.get("‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏•‡∏≤‡∏¢‡πÑ‡∏î‡πâ", 0) > 0:
        recommendations.append("üå± **‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏•‡∏≤‡∏¢‡πÑ‡∏î‡πâ**: ‡πÉ‡∏™‡πà‡∏ñ‡∏±‡∏á‡∏Ç‡∏¢‡∏∞‡πÄ‡∏õ‡∏µ‡∏¢‡∏Å‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥‡∏õ‡∏∏‡πà‡∏¢‡∏´‡∏°‡∏±‡∏Å")
    if category_counts.get("‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢", 0) > 0:
        recommendations.append("‚ö†Ô∏è **‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢**: ‡∏ô‡∏≥‡πÑ‡∏õ‡∏ó‡∏¥‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î‡∏£‡∏±‡∏ö‡∏Ç‡∏¢‡∏∞‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏™‡∏µ‡πÅ‡∏î‡∏á")
    if category_counts.get("‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ", 0) > 0:
        recommendations.append("üóëÔ∏è **‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ**: ‡πÉ‡∏™‡πà‡∏ñ‡∏±‡∏á‡∏Ç‡∏¢‡∏∞‡πÅ‡∏´‡πâ‡∏á‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô")
    
    return recommendations

def create_summary_table(class_counts):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
    results_data = []
    for class_name, data in class_counts.items():
        if class_name in WASTE_CATEGORIES:
            info = WASTE_CATEGORIES[class_name]
            results_data.append({
                "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏¢‡∏∞": f"{info['icon']} {class_name}",
                "‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà": data["category"],
                "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô": data["count"],
                "‡∏ñ‡∏±‡∏á‡∏Ç‡∏¢‡∏∞": f"‡∏ñ‡∏±‡∏á{info['bin_color']}",
                "‡∏ß‡∏¥‡∏ò‡∏µ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£": info["recycle"],
                "Confidence": f"{data['avg_confidence']:.3f}"
            })
    return results_data

def cleanup_memory():
    """‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå memory"""
    try:
        import gc
        gc.collect()
        
        if TORCH_AVAILABLE and torch.cuda.is_available():
            torch.cuda.empty_cache()
    except:
        pass