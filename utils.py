import glob
import os
import numpy as np
import streamlit as st
from config import MODEL_EXTENSIONS, WASTE_CATEGORIES, CLASSES

# ============ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏¥‡∏î warnings ============
import warnings
# ‡∏õ‡∏¥‡∏î warning ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö weights_only
warnings.filterwarnings("ignore", message=".*weights_only.*")
# ‡∏õ‡∏¥‡∏î FutureWarning ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
warnings.filterwarnings("ignore", category=FutureWarning)
# ‡∏õ‡∏¥‡∏î UserWarning ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö torch.load
warnings.filterwarnings("ignore", message=".*torch.load.*")
# ========================================================

# Import dependencies ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError as e:
    ULTRALYTICS_AVAILABLE = False
    st.error(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î Ultralytics ‡πÑ‡∏î‡πâ: {e}")

try:
    import torch
    import torch.nn as nn
    TORCH_AVAILABLE = True
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° safe globals ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö model components ‡∏ï‡πà‡∏≤‡∏á‡πÜ
    safe_globals_list = []
    
    # Lightning components
    try:
        import lightning.fabric.wrappers
        safe_globals_list.append(lightning.fabric.wrappers._FabricModule)
    except ImportError:
        pass
    
    try:
        import lightning.pytorch.core.module
        safe_globals_list.append(lightning.pytorch.core.module.LightningModule)
    except ImportError:
        pass
    
    # TIMM components
    try:
        import timm.models.mobilenetv3
        safe_globals_list.append(timm.models.mobilenetv3.MobileNetV3)
        import timm.models.efficientnet
        safe_globals_list.append(timm.models.efficientnet.EfficientNet)
        import timm.models.resnet
        safe_globals_list.append(timm.models.resnet.ResNet)
    except ImportError:
        pass
    
    # PyTorch components
    safe_globals_list.extend([
        torch.nn.Conv2d,
        torch.nn.BatchNorm2d,
        torch.nn.ReLU,
        torch.nn.ReLU6,
        torch.nn.AdaptiveAvgPool2d,
        torch.nn.Linear,
        torch.nn.Dropout,
        torch.nn.Sequential,
        torch.nn.ModuleList,
        torch.nn.ModuleDict,
        torch.nn.Identity,
        torch.nn.Hardswish,
        torch.nn.Hardsigmoid
    ])
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° safe globals ‡∏ñ‡πâ‡∏≤ PyTorch ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
    if hasattr(torch.serialization, 'add_safe_globals'):
        try:
            torch.serialization.add_safe_globals(safe_globals_list)
            # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° success ‡∏≠‡∏≠‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏£‡∏Å
            # st.success(f"‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° {len(safe_globals_list)} safe globals ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        except Exception as e:
            # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° warning ‡∏≠‡∏≠‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏£‡∏Å
            # st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏û‡∏¥‡πà‡∏° safe globals: {e}")
            pass

except ImportError:
    TORCH_AVAILABLE = False
    st.error("‚ö†Ô∏è PyTorch ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

try:
    import timm
    TIMM_AVAILABLE = True
except ImportError:
    TIMM_AVAILABLE = False
    st.warning("‚ö†Ô∏è TIMM ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

def check_dependencies():
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö dependencies ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
    missing_deps = []
    
    if not ULTRALYTICS_AVAILABLE:
        missing_deps.append("ultralytics")
    if not TORCH_AVAILABLE:
        missing_deps.append("torch")
    if not TIMM_AVAILABLE:
        missing_deps.append("timm")
    
    if missing_deps:
        st.error(f"‚ùå Dependencies ‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢‡πÑ‡∏õ: {', '.join(missing_deps)}")
        st.info("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡πÉ‡∏´‡πâ Streamlit Cloud ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á libraries ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏≠‡∏á refresh ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö")
        return False
    
    return True

def find_model_files():
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• .pt ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
    model_files = []
    for pattern in MODEL_EXTENSIONS:
        try:
            model_files.extend(glob.glob(pattern))
        except Exception as e:
            st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö {pattern}: {e}")
    
    return sorted(model_files)

def safe_torch_load(model_path):
    """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ torch.load ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢"""
    if not TORCH_AVAILABLE:
        raise Exception("PyTorch ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    
    try:
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ö‡∏ö weights_only=True ‡∏Å‡πà‡∏≠‡∏ô
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                checkpoint = torch.load(model_path, map_location='cpu', weights_only=True)
                return checkpoint, 'weights_only_true'
        except Exception as weights_only_error:
            # ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á warning message
            pass
            
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡πÉ‡∏ä‡πâ safe_globals context
        try:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ safe globals ‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
            additional_safe_globals = []
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° TIMM models ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
            timm_models = [
                'timm.models.mobilenetv3.MobileNetV3',
                'timm.models.efficientnet.EfficientNet', 
                'timm.models.resnet.ResNet',
                'timm.models._registry.model_entrypoint'
            ]
            
            for model_name in timm_models:
                try:
                    parts = model_name.split('.')
                    module = __import__('.'.join(parts[:-1]), fromlist=[parts[-1]])
                    cls = getattr(module, parts[-1])
                    additional_safe_globals.append(cls)
                except (ImportError, AttributeError):
                    pass
            
            # ‡∏£‡∏ß‡∏° safe globals ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            all_safe_globals = safe_globals_list + additional_safe_globals
            
            if all_safe_globals and hasattr(torch.serialization, 'safe_globals'):
                with torch.serialization.safe_globals(all_safe_globals):
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        checkpoint = torch.load(model_path, map_location='cpu', weights_only=True)
                        return checkpoint, 'safe_globals'
            else:
                raise Exception("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ safe_globals ‡πÑ‡∏î‡πâ")
                
        except Exception as safe_globals_error:
            # ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á warning message
            pass
            
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ö‡∏ö weights_only=False (unsafe) - ‡∏õ‡∏¥‡∏î warning
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
            return checkpoint, 'unsafe'
            
    except Exception as e:
        raise Exception(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ: {e}")

def detect_model_type(model_path):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• - ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡πâ‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô"""
    try:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏Å‡πà‡∏≠‡∏ô (‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢)
        filename = os.path.basename(model_path).lower()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
        if 'yolo' in filename:
            return 'yolo'
        elif 'efficientnet' in filename or 'efficient' in filename:
            return 'efficientnet'
        elif 'mobilenet' in filename or 'mobile' in filename:
            return 'mobilenet'
        elif 'resnet' in filename:
            return 'resnet'
        
        # ‡∏ñ‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏•‡∏≠‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏î‡∏π (‡∏£‡∏∞‡∏°‡∏±‡∏î‡∏£‡∏∞‡∏ß‡∏±‡∏á)
        try:
            checkpoint, load_method = safe_torch_load(model_path)
            # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° info ‡∏≠‡∏≠‡∏Å
            # st.info(f"üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ: {load_method}")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö structure ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
            if isinstance(checkpoint, dict):
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö keys
                keys = list(checkpoint.keys())
                keys_str = ' '.join(str(k).lower() for k in keys)
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å model object
                if 'model' in checkpoint:
                    model = checkpoint['model']
                    model_str = str(type(model)).lower()
                    
                    if 'efficientnet' in model_str:
                        return 'efficientnet'
                    elif 'mobilenet' in model_str:
                        return 'mobilenet'
                    elif 'yolo' in model_str:
                        return 'yolo'
                    elif hasattr(model, '__class__'):
                        class_name = model.__class__.__name__.lower()
                        if 'efficientnet' in class_name:
                            return 'efficientnet'
                        elif 'mobilenet' in class_name:
                            return 'mobilenet'
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å metadata
                if 'yaml' in keys_str or 'anchors' in keys_str or 'stride' in keys_str:
                    return 'yolo'
                elif 'efficientnet' in keys_str:
                    return 'efficientnet'
                elif 'mobilenet' in keys_str or 'mobile' in keys_str:
                    return 'mobilenet'
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å state_dict structure
                if 'state_dict' in checkpoint:
                    state_keys = list(checkpoint['state_dict'].keys())
                    state_str = ' '.join(state_keys).lower()
                    
                    if any(keyword in state_str for keyword in ['backbone', 'neck', 'head', 'detect']):
                        return 'yolo'
                    elif 'classifier' in state_str or 'features' in state_str:
                        if 'efficientnet' in state_str:
                            return 'efficientnet'
                        elif 'mobilenet' in state_str:
                            return 'mobilenet'
                        else:
                            return 'efficientnet'  # default classification
            
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô model object ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
            elif hasattr(checkpoint, '__class__'):
                class_name = checkpoint.__class__.__name__.lower()
                if 'efficientnet' in class_name:
                    return 'efficientnet'
                elif 'mobilenet' in class_name:
                    return 'mobilenet'
                elif 'yolo' in class_name:
                    return 'yolo'
            
            # Default fallback
            # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° info ‡∏≠‡∏≠‡∏Å
            # st.info("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å structure ‡πÑ‡∏î‡πâ ‡∏à‡∏∞‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô EfficientNet")
            return 'efficientnet'
            
        except Exception as load_error:
            # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° warning ‡∏≠‡∏≠‡∏Å
            # st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {load_error}")
            # ‡∏ñ‡πâ‡∏≤‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏ä‡πâ EfficientNet ‡πÄ‡∏õ‡πá‡∏ô default (‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏õ‡πá‡∏ô classification)
            return 'efficientnet'
        
    except Exception as e:
        # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° warning ‡∏≠‡∏≠‡∏Å
        # st.warning(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {e}")
        return 'efficientnet'  # fallback ‡πÄ‡∏õ‡πá‡∏ô EfficientNet

# ============ ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£ ============
# ‡∏Ñ‡∏•‡∏≤‡∏™‡πÅ‡∏•‡∏∞‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°

class ModelWrapper:
    """Wrapper class ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
    
    def __init__(self, model, model_type='yolo'):
        self.model = model
        self.model_type = model_type
        
    def predict(self, image, conf=0.5, iou=0.45):
        """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"""
        try:
            if self.model_type == 'yolo':
                return self.model(image, conf=conf, iou=iou)
            elif self.model_type in ['efficientnet', 'mobilenet', 'resnet']:
                return self._predict_classification(image, conf)
            else:
                st.error(f"‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏°‡πÄ‡∏î‡∏•: {self.model_type}")
                return None
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {e}")
            return None
    
    def _predict_classification(self, image, conf=0.5):
        """‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• classification"""
        try:
            import torch.nn.functional as F
            from PIL import Image
            import torchvision.transforms as transforms
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            if isinstance(image, np.ndarray):
                image = Image.fromarray(image)
            
            # Transform ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö classification models
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                   std=[0.229, 0.224, 0.225])
            ])
            
            input_tensor = transform(image).unsqueeze(0)
            
            # Prediction
            self.model.eval()
            with torch.no_grad():
                outputs = self.model(input_tensor)
                probabilities = F.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á mock result ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö YOLO format
                if confidence.item() >= conf:
                    mock_result = MockDetectionResult(
                        class_id=predicted.item(),
                        confidence=confidence.item(),
                        image_shape=image.size
                    )
                    return [mock_result]
                else:
                    return []
                
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ classify: {e}")
            return None
    
    def __call__(self, *args, **kwargs):
        """‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô YOLO model"""
        return self.predict(*args, **kwargs)

class MockDetectionResult:
    """Mock class ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà YOLO"""
    
    def __init__(self, class_id, confidence, image_shape):
        self.class_id = class_id
        self.confidence = confidence
        self.image_shape = image_shape
        self.boxes = MockBoxes(class_id, confidence, image_shape)
        self.orig_img = None
    
    def plot(self):
        """Mock plot function"""
        # ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô array ‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ bounding box
        return np.zeros((self.image_shape[1], self.image_shape[0], 3), dtype=np.uint8)

class MockBoxes:
    """Mock boxes ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö classification results"""
    
    def __init__(self, class_id, confidence, image_shape):
        self.data = [{
            'cls': torch.tensor([class_id]),
            'conf': torch.tensor([confidence]),
            'xyxy': torch.tensor([[0, 0, image_shape[0], image_shape[1]]])  # Full image
        }]
    
    def __len__(self):
        return 1 if self.data else 0
    
    def __getitem__(self, index):
        return MockBox(self.data[index])

class MockBox:
    """Mock individual box"""
    
    def __init__(self, data):
        self.cls = data['cls']
        self.conf = data['conf']
        self.xyxy = data['xyxy']

def extract_model_from_checkpoint(checkpoint):
    """‡πÅ‡∏¢‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å checkpoint ‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô"""
    try:
        model = None
        
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô key 'model'
        if isinstance(checkpoint, dict) and 'model' in checkpoint:
            model = checkpoint['model']
            
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô _FabricModule ‡πÉ‡∏´‡πâ‡πÅ‡∏¢‡∏Å module ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
            if hasattr(model, '_forward_module'):
                model = model._forward_module
            elif hasattr(model, 'module'):
                model = model.module
            elif hasattr(model, '_orig_mod'):
                model = model._orig_mod
                
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡∏°‡∏µ state_dict ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà
        elif isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
            # ‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î state_dict
            model = create_model_from_state_dict(checkpoint['state_dict'])
            
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: checkpoint ‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
        elif hasattr(checkpoint, '__class__') and hasattr(checkpoint, 'forward'):
            model = checkpoint
            
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô wrapped module
            if hasattr(model, '_forward_module'):
                model = model._forward_module
            elif hasattr(model, 'module'):
                model = model.module
        
        return model
        
    except Exception as e:
        # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° warning ‡∏≠‡∏≠‡∏Å
        # st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å checkpoint: {e}")
        return None

def create_model_from_state_dict(state_dict):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å state_dict"""
    try:
        if not TIMM_AVAILABLE:
            return None
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå state_dict ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏°‡πÄ‡∏î‡∏•
        keys = list(state_dict.keys())
        keys_str = ' '.join(keys).lower()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™
        num_classes = len(CLASSES)
        for key in keys:
            if 'classifier' in key.lower() or 'head' in key.lower():
                shape = state_dict[key].shape
                if len(shape) >= 2:
                    num_classes = shape[0]
                    break
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
        if 'efficientnet' in keys_str:
            model = timm.create_model('efficientnet_b0', pretrained=False, num_classes=num_classes)
        elif 'mobilenet' in keys_str:
            model = timm.create_model('mobilenetv3_large_100', pretrained=False, num_classes=num_classes)
        else:
            # Default ‡πÄ‡∏õ‡πá‡∏ô EfficientNet
            model = timm.create_model('efficientnet_b0', pretrained=False, num_classes=num_classes)
        
        # ‡πÇ‡∏´‡∏•‡∏î state_dict
        model.load_state_dict(state_dict, strict=False)
        return model
        
    except Exception as e:
        # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° warning ‡∏≠‡∏≠‡∏Å
        # st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å state_dict: {e}")
        return None

@st.cache_resource(show_spinner=False)
def load_model(model_path):
    """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ï‡πà‡∏≤‡∏á‡πÜ - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    if not check_dependencies():
        return None, "‚ùå Dependencies ‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô"
    
    try:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏°‡πÄ‡∏î‡∏•
        model_type = detect_model_type(model_path)
        st.info(f"üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {model_type}")
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ torch ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î memory
        if TORCH_AVAILABLE:
            torch.set_num_threads(2)
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        if not os.path.exists(model_path):
            return None, f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_path}"
        
        with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• {os.path.basename(model_path)}..."):
            
            if model_type == 'yolo':
                # ‡πÇ‡∏´‡∏•‡∏î YOLO model
                try:
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        model = YOLO(model_path)
                    
                    # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ CPU
                    if hasattr(model.model, 'to'):
                        model.model.to('cpu')
                    
                    return ModelWrapper(model, 'yolo'), f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLO ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {os.path.basename(model_path)}"
                
                except Exception as yolo_error:
                    # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° warning ‡∏≠‡∏≠‡∏Å
                    # st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô YOLO: {yolo_error}")
                    # ‡∏ñ‡πâ‡∏≤ YOLO ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏•‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô classification
                    model_type = 'efficientnet'
            
            if model_type in ['efficientnet', 'mobilenet', 'resnet']:
                # ‡πÇ‡∏´‡∏•‡∏î Classification model
                try:
                    checkpoint, load_method = safe_torch_load(model_path)
                    st.info(f"üì• ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ: {load_method}")
                    
                    # ‡πÅ‡∏¢‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å checkpoint
                    model = extract_model_from_checkpoint(checkpoint)
                    
                    if model is None:
                        raise Exception("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å checkpoint ‡πÑ‡∏î‡πâ")
                    
                    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•
                    model.eval()
                    model.to('cpu')
                    
                    return ModelWrapper(model, model_type), f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• {model_type} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (‡∏ß‡∏¥‡∏ò‡∏µ: {load_method}): {os.path.basename(model_path)}"
                
                except Exception as classification_error:
                    error_msg = str(classification_error)
                    st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô classification model: {error_msg}")
                    
                    # Last resort: ‡∏•‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô YOLO ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
                    if "not iterable" in error_msg:
                        st.info("üîÑ ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô YOLO ‡πÅ‡∏ó‡∏ô...")
                        try:
                            with warnings.catch_warnings():
                                warnings.simplefilter("ignore")
                                model = YOLO(model_path)
                            return ModelWrapper(model, 'yolo'), f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô YOLO (fallback): {os.path.basename(model_path)}"
                        except Exception as final_error:
                            return None, f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: {final_error}"
                    
                    return None, f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î classification model: {error_msg}"
            
    except Exception as e:
        error_msg = str(e)
        if "weights_only" in error_msg.lower():
            return None, f"‚ùå ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ PyTorch weights_only: ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLO ‡πÅ‡∏ó‡∏ô"
        elif "not iterable" in error_msg:
            return None, f"‚ùå ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ _FabricModule: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ Lightning Fabric ‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡∏•‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô"
        elif "lightning" in error_msg.lower():
            return None, f"‚ùå ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Lightning Framework: ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ Lightning"
        elif "timm" in error_msg.lower():
            return None, "‚ùå ‡∏Ç‡∏≤‡∏î timm library - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à"
        else:
            return None, f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ: {error_msg}"

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° (process_detections, calculate_environmental_score, etc.)

def process_detections(results, confidence_threshold, iou_threshold):
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á YOLO ‡πÅ‡∏•‡∏∞ Classification"""
    try:
        if not results or len(results) == 0:
            return None, None, None
            
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        result = results[0]
        
        if hasattr(result, 'boxes') and result.boxes is not None:
            detections = result.boxes
        else:
            return None, None, None
        
        if len(detections) == 0:
            return None, None, None
        
        class_counts = {}
        category_counts = {"‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÑ‡∏î‡πâ": 0, "‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏•‡∏≤‡∏¢‡πÑ‡∏î‡πâ": 0, "‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢": 0, "‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ": 0}
        detailed_data = []
        
        for i, detection in enumerate(detections):
            try:
                # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á YOLO format ‡πÅ‡∏•‡∏∞ Mock format
                if hasattr(detection, 'cls'):
                    class_id = int(detection.cls[0])
                    confidence = float(detection.conf[0])
                    
                    if hasattr(detection.xyxy[0], 'cpu'):
                        bbox = detection.xyxy[0].cpu().numpy()
                    else:
                        bbox = detection.xyxy[0].numpy()
                        
                elif isinstance(detection, MockBox):
                    class_id = int(detection.cls[0])
                    confidence = float(detection.conf[0])
                    bbox = detection.xyxy[0].numpy()
                else:
                    continue
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö confidence threshold
                if confidence < confidence_threshold:
                    continue
                
                if class_id < len(CLASSES):
                    class_name = CLASSES[class_id]
                    
                    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏¢‡∏∞
                    if class_name in WASTE_CATEGORIES:
                        info = WASTE_CATEGORIES[class_name]
                        category = info["category"]
                        
                        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
                        if class_name not in class_counts:
                            class_counts[class_name] = {"count": 0, "avg_confidence": 0, "category": category}
                        class_counts[class_name]["count"] += 1
                        class_counts[class_name]["avg_confidence"] += confidence
                        category_counts[category] += 1
                        
                        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
                        detailed_data.append({
                            "ID": i+1,
                            "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó": f"{info['icon']} {class_name}",
                            "‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà": category,
                            "‡∏ß‡∏¥‡∏ò‡∏µ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£": info["recycle"],
                            "‡∏ñ‡∏±‡∏á‡∏Ç‡∏¢‡∏∞": f"‡∏ñ‡∏±‡∏á{info['bin_color']}",
                            "Confidence": f"{confidence:.3f}",
                            "X1": int(bbox[0]) if len(bbox) > 0 else 0,
                            "Y1": int(bbox[1]) if len(bbox) > 1 else 0,
                            "X2": int(bbox[2]) if len(bbox) > 2 else 100,
                            "Y2": int(bbox[3]) if len(bbox) > 3 else 100,
                            "‡∏Ç‡∏ô‡∏≤‡∏î": f"{int(bbox[2]-bbox[0])} x {int(bbox[3]-bbox[1])}" if len(bbox) >= 4 else "Full Image"
                        })
                        
            except Exception as e:
                # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° warning ‡∏≠‡∏≠‡∏Å (‡∏õ‡∏¥‡∏î warning)
                # st.warning(f"‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• detection {i}: {e}")
                continue
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ confidence
        for class_name in class_counts:
            if class_counts[class_name]["count"] > 0:
                class_counts[class_name]["avg_confidence"] /= class_counts[class_name]["count"]
        
        return class_counts, category_counts, detailed_data
    
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {e}")
        return None, None, None

def calculate_environmental_score(category_counts, total_detections):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°"""
    if total_detections == 0:
        return 0, "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡∏¢‡∏∞"
    
    recyclable = category_counts.get("‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÑ‡∏î‡πâ", 0)
    biodegradable = category_counts.get("‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏•‡∏≤‡∏¢‡πÑ‡∏î‡πâ", 0)
    
    eco_score = ((recyclable + biodegradable) / total_detections) * 100
    
    if eco_score >= 80:
        return eco_score, "üåü ‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°! ‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏¢‡∏Å‡∏Ç‡∏¢‡∏∞‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏°‡∏≤‡∏Å"
    elif eco_score >= 60:
        return eco_score, "üëç ‡∏î‡∏µ! ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏¢‡∏Å‡∏Ç‡∏¢‡∏∞‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô"
    elif eco_score >= 40:
        return eco_score, "‚ö° ‡∏û‡∏≠‡πÉ‡∏ä‡πâ ‡πÅ‡∏¢‡∏Å‡∏Ç‡∏¢‡∏∞‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô"
    else:
        return eco_score, "üö® ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á! ‡πÅ‡∏¢‡∏Å‡∏Ç‡∏¢‡∏∞‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°"

def generate_recommendations(category_counts):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏∞"""
    recommendations = []
    
    if category_counts.get("‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÑ‡∏î‡πâ", 0) > 0:
        recommendations.append("‚ôªÔ∏è **‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•**: ‡πÅ‡∏¢‡∏Å‡πÉ‡∏™‡πà‡∏ñ‡∏±‡∏á‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á")
    if category_counts.get("‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏•‡∏≤‡∏¢‡πÑ‡∏î‡πâ", 0) > 0:
        recommendations.append("üå± **‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏•‡∏≤‡∏¢‡πÑ‡∏î‡πâ**: ‡πÉ‡∏™‡πà‡∏ñ‡∏±‡∏á‡∏Ç‡∏¢‡∏∞‡πÄ‡∏õ‡∏µ‡∏¢‡∏Å‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥‡∏õ‡∏∏‡πà‡∏¢‡∏´‡∏°‡∏±‡∏Å")
    if category_counts.get("‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢", 0) > 0:
        recommendations.append("‚ö†Ô∏è **‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢**: ‡∏ô‡∏≥‡πÑ‡∏õ‡∏ó‡∏¥‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î‡∏£‡∏±‡∏ö‡∏Ç‡∏¢‡∏∞‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏™‡∏µ‡πÅ‡∏î‡∏á")
    if category_counts.get("‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ", 0) > 0:
        recommendations.append("üóëÔ∏è **‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ**: ‡πÉ‡∏™‡πà‡∏ñ‡∏±‡∏á‡∏Ç‡∏¢‡∏∞‡πÅ‡∏´‡πâ‡∏á‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô")
    
    return recommendations

def create_summary_table(class_counts):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
    results_data = []
    for class_name, data in class_counts.items():
        if class_name in WASTE_CATEGORIES:
            info = WASTE_CATEGORIES[class_name]
            results_data.append({
                "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏¢‡∏∞": f"{info['icon']} {class_name}",
                "‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà": data["category"],
                "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô": data["count"],
                "‡∏ñ‡∏±‡∏á‡∏Ç‡∏¢‡∏∞": f"‡∏ñ‡∏±‡∏á{info['bin_color']}",
                "‡∏ß‡∏¥‡∏ò‡∏µ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£": info["recycle"],
                "Confidence": f"{data['avg_confidence']:.3f}"
            })
    return results_data

def cleanup_memory():
    """‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå memory"""
    try:
        import gc
        gc.collect()
        
        if TORCH_AVAILABLE and torch.cuda.is_available():
            torch.cuda.empty_cache()
    except:
        pass