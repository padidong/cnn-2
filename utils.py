"""
‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Waste Detection App
‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö YOLO, EfficientNet ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÜ
"""

import glob
import os
import numpy as np
import streamlit as st
from config import MODEL_EXTENSIONS, WASTE_CATEGORIES, CLASSES

# Import dependencies ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError as e:
    ULTRALYTICS_AVAILABLE = False
    st.error(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î Ultralytics ‡πÑ‡∏î‡πâ: {e}")

try:
    import torch
    import torch.nn as nn
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    st.error("‚ö†Ô∏è PyTorch ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

try:
    import timm
    TIMM_AVAILABLE = True
except ImportError:
    TIMM_AVAILABLE = False
    st.warning("‚ö†Ô∏è TIMM ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

def check_dependencies():
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö dependencies ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
    missing_deps = []
    
    if not ULTRALYTICS_AVAILABLE:
        missing_deps.append("ultralytics")
    if not TORCH_AVAILABLE:
        missing_deps.append("torch")
    if not TIMM_AVAILABLE:
        missing_deps.append("timm")
    
    if missing_deps:
        st.error(f"‚ùå Dependencies ‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢‡πÑ‡∏õ: {', '.join(missing_deps)}")
        st.info("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡πÉ‡∏´‡πâ Streamlit Cloud ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á libraries ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏≠‡∏á refresh ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö")
        return False
    
    return True

def find_model_files():
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• .pt ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
    model_files = []
    for pattern in MODEL_EXTENSIONS:
        try:
            model_files.extend(glob.glob(pattern))
        except Exception as e:
            st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö {pattern}: {e}")
    
    return sorted(model_files)

def detect_model_type(model_path):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    try:
        # ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
        checkpoint = torch.load(model_path, map_location='cpu')
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö metadata
        if 'model' in checkpoint:
            model_info = checkpoint.get('model', {})
            if hasattr(model_info, 'yaml') or 'yaml' in str(checkpoint):
                return 'yolo'
            elif 'efficientnet' in str(model_info).lower():
                return 'efficientnet'
            elif 'mobilenet' in str(model_info).lower():
                return 'mobilenet'
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
        filename = os.path.basename(model_path).lower()
        if 'yolo' in filename:
            return 'yolo'
        elif 'efficientnet' in filename or 'efficient' in filename:
            return 'efficientnet'
        elif 'mobilenet' in filename or 'mobile' in filename:
            return 'mobilenet'
        
        # Default ‡πÄ‡∏õ‡πá‡∏ô yolo
        return 'yolo'
        
    except Exception as e:
        st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ: {e}")
        return 'unknown'

class ModelWrapper:
    """Wrapper class ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
    
    def __init__(self, model, model_type='yolo'):
        self.model = model
        self.model_type = model_type
        
    def predict(self, image, conf=0.5, iou=0.45):
        """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"""
        try:
            if self.model_type == 'yolo':
                return self.model(image, conf=conf, iou=iou)
            elif self.model_type in ['efficientnet', 'mobilenet']:
                return self._predict_classification(image, conf)
            else:
                st.error(f"‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏°‡πÄ‡∏î‡∏•: {self.model_type}")
                return None
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {e}")
            return None
    
    def _predict_classification(self, image, conf=0.5):
        """‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• classification"""
        try:
            import torch.nn.functional as F
            from PIL import Image
            import torchvision.transforms as transforms
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            if isinstance(image, np.ndarray):
                image = Image.fromarray(image)
            
            # Transform ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö EfficientNet
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                   std=[0.229, 0.224, 0.225])
            ])
            
            input_tensor = transform(image).unsqueeze(0)
            
            # Prediction
            self.model.eval()
            with torch.no_grad():
                outputs = self.model(input_tensor)
                probabilities = F.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á mock result ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö YOLO format
                mock_result = MockDetectionResult(
                    class_id=predicted.item(),
                    confidence=confidence.item(),
                    image_shape=image.size
                )
                
                return [mock_result] if confidence.item() >= conf else []
                
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ classify: {e}")
            return None
    
    def __call__(self, *args, **kwargs):
        """‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô YOLO model"""
        return self.predict(*args, **kwargs)

class MockDetectionResult:
    """Mock class ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà YOLO"""
    
    def __init__(self, class_id, confidence, image_shape):
        self.class_id = class_id
        self.confidence = confidence
        self.image_shape = image_shape
        self.boxes = MockBoxes(class_id, confidence, image_shape)
        self.orig_img = None
    
    def plot(self):
        """Mock plot function"""
        # ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô array ‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ bounding box
        return np.zeros((self.image_shape[1], self.image_shape[0], 3), dtype=np.uint8)

class MockBoxes:
    """Mock boxes ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö classification results"""
    
    def __init__(self, class_id, confidence, image_shape):
        self.data = [{
            'cls': torch.tensor([class_id]),
            'conf': torch.tensor([confidence]),
            'xyxy': torch.tensor([[0, 0, image_shape[0], image_shape[1]]])  # Full image
        }]
    
    def __len__(self):
        return 1 if self.data else 0
    
    def __getitem__(self, index):
        return MockBox(self.data[index])

class MockBox:
    """Mock individual box"""
    
    def __init__(self, data):
        self.cls = data['cls']
        self.conf = data['conf']
        self.xyxy = data['xyxy']

@st.cache_resource(show_spinner=False)
def load_model(model_path):
    """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
    if not check_dependencies():
        return None, "‚ùå Dependencies ‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô"
    
    try:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏°‡πÄ‡∏î‡∏•
        model_type = detect_model_type(model_path)
        st.info(f"üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {model_type}")
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ torch ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î memory
        if TORCH_AVAILABLE:
            torch.set_num_threads(2)
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        if not os.path.exists(model_path):
            return None, f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_path}"
        
        with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• {os.path.basename(model_path)}..."):
            
            if model_type == 'yolo':
                # ‡πÇ‡∏´‡∏•‡∏î YOLO model
                model = YOLO(model_path)
                
                # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ CPU
                if hasattr(model.model, 'to'):
                    model.model.to('cpu')
                
                return ModelWrapper(model, 'yolo'), f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLO ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {os.path.basename(model_path)}"
                
            elif model_type in ['efficientnet', 'mobilenet']:
                # ‡πÇ‡∏´‡∏•‡∏î EfficientNet/MobileNet model
                checkpoint = torch.load(model_path, map_location='cpu')
                
                if 'model' in checkpoint:
                    model = checkpoint['model']
                elif 'state_dict' in checkpoint:
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î state_dict
                    model = create_efficientnet_model()
                    model.load_state_dict(checkpoint['state_dict'])
                else:
                    model = checkpoint
                
                # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•
                model.eval()
                model.to('cpu')
                
                return ModelWrapper(model, model_type), f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• {model_type} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {os.path.basename(model_path)}"
            
            else:
                # ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô YOLO ‡∏Å‡πà‡∏≠‡∏ô
                try:
                    model = YOLO(model_path)
                    if hasattr(model.model, 'to'):
                        model.model.to('cpu')
                    return ModelWrapper(model, 'yolo'), f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (YOLO): {os.path.basename(model_path)}"
                except:
                    return None, f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ: ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏°‡πÄ‡∏î‡∏•"
            
    except Exception as e:
        error_msg = str(e)
        if "timm" in error_msg.lower():
            return None, "‚ùå ‡∏Ç‡∏≤‡∏î timm library - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à"
        elif "lightning" in error_msg.lower():
            return None, "‚ùå ‡∏Ç‡∏≤‡∏î pytorch-lightning - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à"
        elif "efficientnet" in error_msg.lower():
            return None, f"‚ùå ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏±‡∏ö EfficientNet model: {error_msg}"
        else:
            return None, f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ: {error_msg}"

def create_efficientnet_model():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• EfficientNet"""
    try:
        import timm
        # ‡πÉ‡∏ä‡πâ EfficientNet ‡∏à‡∏≤‡∏Å timm
        model = timm.create_model('efficientnet_b0', pretrained=False, num_classes=len(CLASSES))
        return model
    except Exception as e:
        st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á EfficientNet model: {e}")
        return None

def process_detections(results, confidence_threshold, iou_threshold):
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á YOLO ‡πÅ‡∏•‡∏∞ Classification"""
    try:
        if not results or len(results) == 0:
            return None, None, None
            
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        result = results[0]
        
        if hasattr(result, 'boxes') and result.boxes is not None:
            detections = result.boxes
        else:
            return None, None, None
        
        if len(detections) == 0:
            return None, None, None
        
        class_counts = {}
        category_counts = {"‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÑ‡∏î‡πâ": 0, "‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏•‡∏≤‡∏¢‡πÑ‡∏î‡πâ": 0, "‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢": 0, "‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ": 0}
        detailed_data = []
        
        for i, detection in enumerate(detections):
            try:
                # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á YOLO format ‡πÅ‡∏•‡∏∞ Mock format
                if hasattr(detection, 'cls'):
                    class_id = int(detection.cls[0])
                    confidence = float(detection.conf[0])
                    
                    if hasattr(detection.xyxy[0], 'cpu'):
                        bbox = detection.xyxy[0].cpu().numpy()
                    else:
                        bbox = detection.xyxy[0].numpy()
                        
                elif isinstance(detection, MockBox):
                    class_id = int(detection.cls[0])
                    confidence = float(detection.conf[0])
                    bbox = detection.xyxy[0].numpy()
                else:
                    continue
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö confidence threshold
                if confidence < confidence_threshold:
                    continue
                
                if class_id < len(CLASSES):
                    class_name = CLASSES[class_id]
                    
                    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏¢‡∏∞
                    if class_name in WASTE_CATEGORIES:
                        info = WASTE_CATEGORIES[class_name]
                        category = info["category"]
                        
                        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
                        if class_name not in class_counts:
                            class_counts[class_name] = {"count": 0, "avg_confidence": 0, "category": category}
                        class_counts[class_name]["count"] += 1
                        class_counts[class_name]["avg_confidence"] += confidence
                        category_counts[category] += 1
                        
                        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
                        detailed_data.append({
                            "ID": i+1,
                            "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó": f"{info['icon']} {class_name}",
                            "‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà": category,
                            "‡∏ß‡∏¥‡∏ò‡∏µ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£": info["recycle"],
                            "‡∏ñ‡∏±‡∏á‡∏Ç‡∏¢‡∏∞": f"‡∏ñ‡∏±‡∏á{info['bin_color']}",
                            "Confidence": f"{confidence:.3f}",
                            "X1": int(bbox[0]) if len(bbox) > 0 else 0,
                            "Y1": int(bbox[1]) if len(bbox) > 1 else 0,
                            "X2": int(bbox[2]) if len(bbox) > 2 else 100,
                            "Y2": int(bbox[3]) if len(bbox) > 3 else 100,
                            "‡∏Ç‡∏ô‡∏≤‡∏î": f"{int(bbox[2]-bbox[0])} x {int(bbox[3]-bbox[1])}" if len(bbox) >= 4 else "N/A"
                        })
                        
            except Exception as e:
                st.warning(f"‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• detection {i}: {e}")
                continue
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ confidence
        for class_name in class_counts:
            if class_counts[class_name]["count"] > 0:
                class_counts[class_name]["avg_confidence"] /= class_counts[class_name]["count"]
        
        return class_counts, category_counts, detailed_data
    
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {e}")
        return None, None, None

def calculate_environmental_score(category_counts, total_detections):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°"""
    if total_detections == 0:
        return 0, "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡∏¢‡∏∞"
    
    recyclable = category_counts.get("‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÑ‡∏î‡πâ", 0)
    biodegradable = category_counts.get("‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏•‡∏≤‡∏¢‡πÑ‡∏î‡πâ", 0)
    
    eco_score = ((recyclable + biodegradable) / total_detections) * 100
    
    if eco_score >= 80:
        return eco_score, "üåü ‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°! ‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏¢‡∏Å‡∏Ç‡∏¢‡∏∞‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏°‡∏≤‡∏Å"
    elif eco_score >= 60:
        return eco_score, "üëç ‡∏î‡∏µ! ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏¢‡∏Å‡∏Ç‡∏¢‡∏∞‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô"
    elif eco_score >= 40:
        return eco_score, "‚ö° ‡∏û‡∏≠‡πÉ‡∏ä‡πâ ‡πÅ‡∏¢‡∏Å‡∏Ç‡∏¢‡∏∞‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô"
    else:
        return eco_score, "üö® ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á! ‡πÅ‡∏¢‡∏Å‡∏Ç‡∏¢‡∏∞‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°"

def generate_recommendations(category_counts):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏∞"""
    recommendations = []
    
    if category_counts.get("‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡πÑ‡∏î‡πâ", 0) > 0:
        recommendations.append("‚ôªÔ∏è **‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•**: ‡πÅ‡∏¢‡∏Å‡πÉ‡∏™‡πà‡∏ñ‡∏±‡∏á‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á")
    if category_counts.get("‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏•‡∏≤‡∏¢‡πÑ‡∏î‡πâ", 0) > 0:
        recommendations.append("üå± **‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏•‡∏≤‡∏¢‡πÑ‡∏î‡πâ**: ‡πÉ‡∏™‡πà‡∏ñ‡∏±‡∏á‡∏Ç‡∏¢‡∏∞‡πÄ‡∏õ‡∏µ‡∏¢‡∏Å‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥‡∏õ‡∏∏‡πà‡∏¢‡∏´‡∏°‡∏±‡∏Å")
    if category_counts.get("‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢", 0) > 0:
        recommendations.append("‚ö†Ô∏è **‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢**: ‡∏ô‡∏≥‡πÑ‡∏õ‡∏ó‡∏¥‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î‡∏£‡∏±‡∏ö‡∏Ç‡∏¢‡∏∞‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏™‡∏µ‡πÅ‡∏î‡∏á")
    if category_counts.get("‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ", 0) > 0:
        recommendations.append("üóëÔ∏è **‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ**: ‡πÉ‡∏™‡πà‡∏ñ‡∏±‡∏á‡∏Ç‡∏¢‡∏∞‡πÅ‡∏´‡πâ‡∏á‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô")
    
    return recommendations

def create_summary_table(class_counts):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
    results_data = []
    for class_name, data in class_counts.items():
        if class_name in WASTE_CATEGORIES:
            info = WASTE_CATEGORIES[class_name]
            results_data.append({
                "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏¢‡∏∞": f"{info['icon']} {class_name}",
                "‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà": data["category"],
                "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô": data["count"],
                "‡∏ñ‡∏±‡∏á‡∏Ç‡∏¢‡∏∞": f"‡∏ñ‡∏±‡∏á{info['bin_color']}",
                "‡∏ß‡∏¥‡∏ò‡∏µ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£": info["recycle"],
                "Confidence": f"{data['avg_confidence']:.3f}"
            })
    return results_data

def cleanup_memory():
    """‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå memory"""
    try:
        import gc
        gc.collect()
        
        if TORCH_AVAILABLE and torch.cuda.is_available():
            torch.cuda.empty_cache()
    except:
        pass